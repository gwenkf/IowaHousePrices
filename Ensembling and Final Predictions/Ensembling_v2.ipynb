{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ensembling of Various Models: Voting and Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "#options for display\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('display.max_rows', 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and test data :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('../Data/train_x2.csv')\n",
    "train_y = pd.read_csv('../Data/train_y2.csv',header=None)\n",
    "train_y = train_y.values.ravel()\n",
    "test_x = pd.read_csv('../Data/test_x2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Scoring Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train_x.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train_x.values, train_y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries for specific Ensembled Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Linear Models\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "\n",
    "\n",
    "#Kernel Ridge Regression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "\n",
    "#Gradient Boosting Machines\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Support Vector Machines\n",
    "from sklearn import svm\n",
    "\n",
    "#Others\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso (Elastic went to Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso = make_pipeline(Lasso(alpha =0.0003, random_state=1))\n",
    "elastic = ElasticNet(alpha= 0.0049, fit_intercept = True, l1_ratio= 0.61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12039872717670055"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsle_cv(lasso).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KRR_deg3 = KernelRidge(alpha=10, kernel='polynomial', degree=3, coef0=4)\n",
    "KRR_deg2 =KernelRidge(alpha=1, kernel='polynomial', degree=2, coef0=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KRR deg 3:  0.116524207789\n",
      "KRR deg 2:  0.116519269316\n"
     ]
    }
   ],
   "source": [
    "print(\"KRR deg 3: \", rmsle_cv(KRR_deg3).mean())\n",
    "print(\"KRR deg 2: \", rmsle_cv(KRR_deg2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth = 2, max_features = 12, min_samples_split = 10, subsample = 0.7,\n",
    "     random_state=42, learning_rate = 0.01, n_estimators = 4000, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBR:  0.114690038171\n"
     ]
    }
   ],
   "source": [
    "print(\"GBR: \", rmsle_cv(gbr).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randomforest1 = RandomForestRegressor(n_estimators=800, max_features=13, random_state=43, oob_score=True,max_depth=7)\n",
    "randomforest2 = RandomForestRegressor(n_estimators=600, max_features=8, random_state=43, oob_score=True,max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF deep:  0.149590737861\n",
      "RF shallow:  0.220055339749\n"
     ]
    }
   ],
   "source": [
    "print(\"RF deep: \", rmsle_cv(randomforest1).mean())\n",
    "print(\"RF shallow: \", rmsle_cv(randomforest2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm1 = svm.SVR(C=9, epsilon=.009, degree = 1, kernel='poly')\n",
    "svm2 = svm.SVR(C =11, epsilon = 0.03, gamma =0.0002, kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 1:  0.120619069159\n",
      "SVM 2:  0.118384662385\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM 1: \", rmsle_cv(svm1).mean())\n",
    "print(\"SVM 2: \", rmsle_cv(svm2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ok, let's average models then try a more complex ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a class that takes models, fits them, then averages them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out a few linear models. General Linear Lasso, Kernel Ridge Regression, and Gradient Boost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Averaged base models score: 0.1126 (0.0038)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (lasso, elastic, KRR_deg3, KRR_deg2, gbr, svm1, svm2))\n",
    "\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AveragingModels(models=(Pipeline(steps=[('lasso', Lasso(alpha=0.0003, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=1,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))]), ElasticNet(alpha=0.0049, copy_X=True, fit_intercept=True, l1_ratio=0.61... epsilon=0.03, gamma=0.0002,\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_models.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = averaged_models.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame({'Id' : (np.arange(len(test_x))+1461),\n",
    "            'SalePrice': np.exp(predictions)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction.to_csv(path_or_buf=\"../predictions_avg_data2.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model:  CV, Public LB Score, Data\n",
    "average with all models: .126? (LB), new data\n",
    "average without rf2: 0.114 (CV), 0.1234 (LB), new data\n",
    "average without both rf's: 0.113(CV), 0.1245 (LB), new data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Oh it improves it!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "Well let's move on to the fancy ass ensemble...\n",
    "Get each model's sale price prediction (on the out of bag fold), and use that as input to another model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred.flatten()\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stack them up, and use a meta model to decide based on the new stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Gboost as meta-model for now in case there are non-linearities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfmeta = RandomForestRegressor(n_estimators=800)\n",
    "gbrmeta = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Averaged models score: 0.1108 (0.0058)\n"
     ]
    }
   ],
   "source": [
    "# First, we ran meta = Random Forests:\n",
    "# stacked_averaged_models = StackingAveragedModels(base_models = (lasso, elastic, KRR_deg3, KRR_deg2, gbr, randomforest1, randomforest2, svm1, svm2),\n",
    "#                                                  meta_model = rfmeta)\n",
    "# Second, we ran meta = lasso\n",
    "stacked_averaged_models = StackingAveragedModels(base_models = (lasso, elastic, KRR_deg3, KRR_deg2, gbr, randomforest1, svm1, svm2),\n",
    "                                                 meta_model = gbrmeta)\n",
    "\n",
    "score_stacked_model = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score_stacked_model.mean(), score_stacked_model.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for meta_model = lasso we got Stacking Average models score: 0.1103 (0.0048)\n",
    "# for rfmeta = lasso we got Stacking Average models score: 0.1115 (0.0053)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stack_rf = stacked_averaged_models\n",
    "stack_mod = stacked_averaged_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingAveragedModels(base_models=(Pipeline(steps=[('lasso', Lasso(alpha=0.0003, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=1,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))]), ElasticNet(alpha=0.0049, copy_X=True, fit_intercept=True, l1_ratio... epsilon=0.03, gamma=0.0002,\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)),\n",
       "            meta_model=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "             warm_start=False),\n",
       "            n_folds=5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack_rf.fit(train_x.values, train_y)\n",
    "stack_mod.fit(train_x.values, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred_stack_rf = stack_rf.predict(test_x.values)\n",
    "pred_stack = stack_mod.predict(test_x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11.62302318,  12.00825159,  12.13360146, ...,  12.00825159,\n",
       "        11.65702765,  12.36062561])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred_stack_rf\n",
    "pred_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_stack_rf = pd.DataFrame({'Id' : (np.arange(len(test_x))+1461),\n",
    "#             'SalePrice': np.exp(pred_stack_rf)})\n",
    "pred_stack = pd.DataFrame({'Id' : (np.arange(len(test_x))+1461),\n",
    "            'SalePrice': np.exp(pred_stack)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred_stack_rf.to_csv(path_or_buf=\"../Data/predictions_stackrf_data2.csv\",index=None)\n",
    "pred_stack.to_csv(path_or_buf=\"../Data/predictions_stacklasso_data2.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scores\n",
    "stacked without rf2: CV 0.1108 (0.006sd), LB 0.1355, new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
