{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reading in the data to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 181)\n",
      "(1458, 181)\n",
      "(1458, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv('../Data/test_x2.csv')\n",
    "X = pd.read_csv('../Data/train_x2.csv')\n",
    "y = pd.read_csv('../Data/train_y2.csv', header = None)\n",
    "print(X_test.shape)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Gradient Boosting (book, p. 198)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.02, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=1250, presort='auto', random_state=42,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=3, n_estimators=3000, random_state=42, learning_rate = 0.02,\n",
    "                                min_samples_leaf = 15, min_samples_split=10)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_val, y_pred)\n",
    "          for y_pred in gbrt.staged_predict(X_val)]\n",
    "bst_n_estimators = np.argmin(errors)\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=3, n_estimators=bst_n_estimators, random_state=42, learning_rate = 0.02)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_n_estimators  # 270 (OUT OF 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014989687644554045"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(errors) # 0.014635885043588544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12243237988601727"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(errors)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_model = GradientBoostingRegressor(random_state=42, learning_rate = 0.01)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "grid_para_boost = [\n",
    "    {'max_depth': [2],\n",
    "     'min_samples_split': [10],  # [8, 9, 10, 11],\n",
    "     'max_features': [11,12],  #[12, 14, 16],\n",
    "      'subsample': [0.6, 0.7, 0.8],   # [0.5, 0.6, 0.7],\n",
    "      'n_estimators': [10000]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.01, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=42,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'max_depth': [2], 'min_samples_split': [10], 'max_features': [11, 12], 'subsample': [0.6, 0.7, 0.8], 'n_estimators': [10000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_boost = model_selection.GridSearchCV(boost_model, grid_para_boost, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "grid_search_boost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2,\n",
       " 'max_features': 11,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 10000,\n",
       " 'subsample': 0.6}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_boost.best_params_\n",
    "# Best parameters I found first time: {'max_depth': 2, 'max_features': 10, 'min_samples_split': 14}\n",
    "# Second time I ran it I got best params: {'max_depth': 2, 'max_features': 10, 'min_samples_split': 12, 'subsample': 0.8}\n",
    "# Third time I ran it I got best params: {'max_depth': 2, 'max_features': 12, 'min_samples_split': 10, 'subsample': 0.7}\n",
    "# Fourtt time I ran it I got best params: {'max_depth': 2, 'max_features': 12, 'min_samples_split': 10, 'n_estimators': 9000, 'subsample': 0.6}\n",
    "# Fifth time I ran: {'max_depth': 2,  'max_features': 12,  'min_samples_split': 10,  'n_estimators': 9000,  'subsample': 0.5}\n",
    "# Sixths time I ran: {'max_depth': 2,  'max_features': 15,  'min_samples_split': 8, 'n_estimators': 11000, 'subsample': 0.6}\n",
    "# Seventh time I ran - with learning rate 0.01: {'max_depth': 2,  'max_features': 14,  'min_samples_split': 8,  'n_estimators': 10000,'subsample': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0027569935680823816"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_boost.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11513383626706555"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytrees = list()\n",
    "myerr = list()\n",
    "for rand in range(20):\n",
    "\n",
    "    print(rand)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, np.ravel(y), random_state = rand)\n",
    "    gbrt = GradientBoostingRegressor(max_depth = 2, max_features = 11, min_samples_split = 10, subsample = 0.6,\n",
    "     random_state=42, learning_rate = 0.01, n_estimators = 5000, verbose = 0)\n",
    "# First time I used (random state was undefined):\n",
    "# gbrt = GradientBoostingRegressor(max_depth = 2, max_features = 10, min_samples_split = 14,\n",
    "#     random_state=42, learning_rate = 0.02, n_estimators = 100000, verbose = 0)\n",
    "# Second time I used (random state was undefined):\n",
    "# gbrt = GradientBoostingRegressor(max_depth = 2, max_features = 10, min_samples_split = 12, subsample = 0.8,\n",
    "#     random_state=42, learning_rate = 0.02, n_estimators = 100000, verbose = 0)\n",
    "# Third time I used (with random_state = 123):\n",
    "# gbrt = GradientBoostingRegressor(max_depth = 2, max_features = 12, min_samples_split = 10, subsample = 0.7,\n",
    "#     random_state=42, learning_rate = 0.02, n_estimators = 10000, verbose = 0)\n",
    "# Fifths time:\n",
    "# gbrt = GradientBoostingRegressor(max_depth = 2, max_features = 12, min_samples_split = 10, subsample = 0.5,\n",
    "#     random_state=42, learning_rate = 0.02, n_estimators = 10000, verbose = 0)\n",
    "# Sixths time:\n",
    "# gbrt = GradientBoostingRegressor(max_depth = 2, max_features = 15, min_samples_split = 8, subsample = 0.6, \n",
    "#                                    random_state=42, learning_rate = 0.02, n_estimators = 8000, verbose = 0)\n",
    "# With the new data first time:\n",
    "# gbrt = GradientBoostingRegressor(max_depth = 2, max_features = 12, min_samples_split = 10, subsample = 0.7,\n",
    "#      random_state=42, learning_rate = 0.01, n_estimators = 10000, verbose = 0)\n",
    "\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    errors = [mean_squared_error(y_val, y_pred)**0.5 for y_pred in gbrt.staged_predict(X_val)]\n",
    "    bst_n_estimators = np.argmin(errors)\n",
    "\n",
    "    mytrees.append(bst_n_estimators)\n",
    "    myerr.append(min(errors))\n",
    "\n",
    "# gbrt_best = GradientBoostingRegressor()\n",
    "# gbrt_best.fit(X_train, y_train)\n",
    "# First time, the best number of trees was 6,706 and its error was 0.11978486920254075\n",
    "# Second time, the best number of trees was 5,449 and its error was 0.11386754321967392 or, with random_state 123 above \n",
    "# the error was 0.1111 for the best number of trees 6,233\n",
    "# Third time, the best number of trees was 3,916 and its error was 0.11005619929888709 (with traintest random state=123)\n",
    "# and when random state for train-test split was = 12, the best number of trees was 8942, and error 0.1117828243038694\n",
    "# and for range(20) average RMSE across 20 runs was: 0.11822365072318571\n",
    "# Fourth time, the best number of trees was 4433 and random state was 12 and error 0.111, \n",
    "# but for random state 123 it was 5309 trees and error 0.11034254374190201.\n",
    "# Firth time I got 5705 trees for random state 123 and error: 0.11005303800608779\n",
    "# and for random state 12 - 5831 trees and error: 0.11294471708044936\n",
    "# and for range(20) average RMSE across 20 runs was: 0.11818895489231944\n",
    "# Sixth time:\n",
    "# and for range(20) average RMSE across 20 runs was: 0.11918941133084104\n",
    "# Seventh time: 0.11843656398659105 - best estimators 8672\n",
    "np.mean(myerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4054"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_n_estimators  # 270 (OUT OF 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12362774625269257"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, np.ravel(y))\n",
    "gbrt_last = GradientBoostingRegressor(max_depth = 2, max_features = 11, min_samples_split = 10, subsample = 0.6,\n",
    "     random_state=42, learning_rate = 0.01, n_estimators = 5000, verbose = 0)\n",
    "gbrt_last.fit(X_train, y_train)\n",
    "y_pred = gbrt_last.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.       ,  0.9553868],\n",
       "       [ 0.9553868,  1.       ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(y_val, y_pred)  # Correlation is 0.95758691! - based on the updated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
